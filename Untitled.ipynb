{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09226c79-a848-4a14-8175-de4b30bedcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FEATURES = 2 # minimum and maximum temp\n",
    "\n",
    "# Function to load data\n",
    "def load_data(picklefile):\n",
    "    f = open(picklefile, \"rb\")\n",
    "    dict = pickle.load(f)\n",
    "    f.close()\n",
    "    return dict[\"Perth_Airport\"], dict[\"Perth_Metro\"]\n",
    "PerthA_df, PerthM_df = load_data(\"temperatures.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa469ad0-6af7-4098-8664-4f8ef1f6e67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1944-06</th>\n",
       "      <td>8.1</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-07</th>\n",
       "      <td>7.7</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-08</th>\n",
       "      <td>7.1</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-09</th>\n",
       "      <td>7.9</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-10</th>\n",
       "      <td>10.5</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min   max\n",
       "date               \n",
       "1944-06   8.1  20.4\n",
       "1944-07   7.7  18.3\n",
       "1944-08   7.1  19.5\n",
       "1944-09   7.9  20.3\n",
       "1944-10  10.5  24.6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PerthA_df.columns = [\"min\", \"max\"] #renaming column for easy of use\n",
    "PerthM_df.columns = [\"min\", \"max\"]\n",
    "PerthA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7b4de4-c71a-4e0c-b2d2-42781e31fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def split_data(df, inputs_length, targets_length, batch_size=32, shuffle=True, seed=42):\n",
    "    # an inner function to do the splitting\n",
    "    def split_inputs_and_targets(tf_ds):\n",
    "        return tf_ds[:, :-targets_length], tf_ds[:, -targets_length:]\n",
    "    if batch_size == -1:\n",
    "        batch_size = df.shape[0]\n",
    "    return tf.keras.utils.timeseries_dataset_from_array(\n",
    "        tf.convert_to_tensor(df, dtype=tf.float32),\n",
    "        targets = None,\n",
    "        sequence_length = inputs_length + targets_length,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = seed\n",
    "    ).map(split_inputs_and_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89302bbc-f431-416d-b325-f23949f9cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f11d765-a86b-4a29-8419-1e15a566182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "PerthA_scaled = scaler.fit_transform(PerthA_df)\n",
    "PerthA_df_scaled = pd.DataFrame(PerthA_scaled, index=PerthA_df.index, columns=PerthA_df.columns)\n",
    "\n",
    "# Apply the same transformation to validation and test data\n",
    "PerthM_scaled = scaler.transform(PerthM_df)\n",
    "PerthM_df_scaled = pd.DataFrame(PerthM_scaled, index=PerthM_df.index, columns=PerthM_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1028bd4f-c9da-49f6-81dd-8407d569092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(inputs_length, targets_length, batch_size_train=32, model_type='model1'):\n",
    "    \"\"\"\n",
    "    Prepares training, validation, and test datasets with specified input and target lengths.\n",
    "\n",
    "    Parameters:\n",
    "    - inputs_length: Length of input sequences.\n",
    "    - targets_length: Length of target sequences.\n",
    "    - batch_size_train: Batch size for the training dataset.\n",
    "    - model_type: 'model1' for Models 1 and 2, 'model3' for the Encoder-Decoder model.\n",
    "\n",
    "    Returns:\n",
    "    - train_ds, val_ds, test_ds: TensorFlow datasets.\n",
    "    \"\"\"\n",
    "    # Select the appropriate data preparation function based on model_type\n",
    "    if model_type == 'model1':\n",
    "        split_fn = split_data  # For Models 1 and 2\n",
    "    elif model_type == 'model3':\n",
    "        split_fn = prepare_encoder_decoder_data_internal  # For Model 3\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Use 'model1' or 'model3'.\")\n",
    "\n",
    "    # Training dataset\n",
    "    train_ds = split_fn(\n",
    "        df=PerthA_df_scaled,\n",
    "        inputs_length=inputs_length,\n",
    "        targets_length=targets_length,\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Validation dataset\n",
    "    val_ds = split_fn(\n",
    "        df=PerthM_df_scaled.loc['1994-01':'2013-12'],\n",
    "        inputs_length=inputs_length,\n",
    "        targets_length=targets_length,\n",
    "        batch_size=-1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Test dataset\n",
    "    test_ds = split_fn(\n",
    "        df=PerthM_df_scaled.loc['2014-01':],\n",
    "        inputs_length=inputs_length,\n",
    "        targets_length=targets_length,\n",
    "        batch_size=-1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b8496-8683-4005-8bea-d49c9f6d3137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
